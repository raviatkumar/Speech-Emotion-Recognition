# Speech Emotion Recognition

![Alt text](https://raw.githubusercontent.com/raviatkumar/Speech-Emotion-Recognition/main/Image/Voice.jpg)


## Problem Statement:

In the realm of Speech Emotion Recognition, the CREMA-D dataset stands out as a comprehensive and diverse collection comprising 7,442 original audio clips sourced from 91 actors. This dataset offers a unique advantage due to the extensive variability it presents, featuring contributions from 48 male and 43 female actors spanning a wide age range of 20 to 74, and representing a diverse array of races and ethnicities, including African American, Asian, Caucasian, Hispanic, and Unspecified. Each actor vocalizes a selection of 12 sentences, expressing a spectrum of six distinct emotions: Anger, Disgust, Fear, Happy, Neutral, and Sad. Adding to the complexity, the dataset introduces four emotion levels, categorized as Low, Medium, High, and Unspecified. The significance of CREMA-D lies in its richness of speakers, ensuring that any model trained on this dataset is poised to generalize effectively across diverse datasets, mitigating the risk of overfitting that often arises in more homogenous speaker datasets. In light of these attributes, the problem at hand involves the development of an emotion classifier capable of accurately discerning and categorizing emotions from audio data, leveraging the wealth of information encapsulated within the CREMA-D dataset.




